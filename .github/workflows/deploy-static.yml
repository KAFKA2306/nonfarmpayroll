name: Deploy Static Dashboard

on:
  # Manual trigger only - use this for UI updates without data collection
  workflow_dispatch:
    inputs:
      use_demo_data:
        description: 'Use demo data if real data unavailable'
        required: false
        default: 'true'
        type: boolean

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages-static"
  cancel-in-progress: false

jobs:
  deploy-static:
    runs-on: ubuntu-latest
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python (for demo data generation if needed)
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install basic dependencies
      run: |
        pip install pandas numpy requests
        
    - name: Prepare dashboard files
      run: |
        mkdir -p docs
        
        # Copy static dashboard files
        cp dashboard.html docs/index.html
        cp dashboard.css docs/
        cp dashboard.js docs/
        
        # Check if processed data exists, if not create demo data
        if [ ! -f "data_processed/nfp_revisions.csv" ] && [ "${{ inputs.use_demo_data }}" == "true" ]; then
          echo "Creating demo data for dashboard preview..."
          mkdir -p data_processed
          cat > create_demo_data.py << 'EOF'
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json

# Generate demo employment data
dates = pd.date_range("1990-01-01", "2024-12-01", freq="MS")
np.random.seed(42)

# Realistic employment trend
base_trend = np.linspace(120000, 160000, len(dates))
seasonal = 2000 * np.sin(2 * np.pi * np.arange(len(dates)) / 12)
noise = np.random.normal(0, 500, len(dates))
employment = base_trend + seasonal + noise

# Create revision patterns
revision_noise = np.random.normal(15, 75, len(dates))
df = pd.DataFrame({
    "date": dates,
    "final": employment.astype(int),
    "release1": (employment - revision_noise).astype(int),
    "release2": (employment - revision_noise * 0.4).astype(int),
    "release3": (employment - revision_noise * 0.1).astype(int),
    "rev_final": revision_noise.astype(int),
    "se": 85,
    "ci90_lower": (employment - revision_noise - 136).astype(int),
    "ci90_upper": (employment - revision_noise + 136).astype(int),
    "is_outlier": False,
    "revision_magnitude": "Medium"
})

# Flag some outlier periods
covid_mask = (df["date"] >= "2020-03-01") & (df["date"] <= "2020-06-01")
df.loc[covid_mask, "is_outlier"] = True

# Save demo data
df.to_csv("data_processed/nfp_revisions.csv", index=False)

# Create demo summary
summary = {
    "dataset_info": {
        "total_records": len(df),
        "date_range": {
            "start": str(df["date"].min().date()),
            "end": str(df["date"].max().date())
        },
        "latest_employment": float(df["final"].iloc[-1]),
        "processing_timestamp": datetime.now().isoformat()
    },
    "revision_statistics": {
        "mean_revision": float(df["rev_final"].mean()),
        "median_revision": float(df["rev_final"].median()),
        "std_revision": float(df["rev_final"].std()),
        "max_positive": float(df["rev_final"].max()),
        "max_negative": float(df["rev_final"].min())
    },
    "uncertainty_analysis": {
        "bls_statistical_error": 85.0,
        "revision_uncertainty": float(df["rev_final"].std()),
        "combined_uncertainty": float(np.sqrt(85.0**2 + df["rev_final"].std()**2))
    }
}

with open("data_processed/summary_report.json", "w") as f:
    json.dump(summary, f, indent=2)

print("Demo data created successfully")
EOF
          python3 create_demo_data.py
          rm create_demo_data.py
        fi
        
        # Copy data files (real or demo)
        if [ -d "data_processed" ]; then
          cp -r data_processed docs/
        fi
        
        # Create status and timestamp files
        echo "$(date -u +"%Y-%m-%d %H:%M:%S UTC")" > docs/last_updated.txt
        
        cat > docs/status.json << EOF
        {
          "status": "operational",
          "deployment_type": "static",
          "last_updated": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
          "data_source": "${{ github.event.inputs.use_demo_data == 'true' && 'demo' || 'existing' }}",
          "workflow_run": "${{ github.run_id }}",
          "commit_sha": "${{ github.sha }}"
        }
        EOF
        
        # Add a banner to demo deployments
        if [ "${{ inputs.use_demo_data }}" == "true" ]; then
          sed -i 's/<body>/<body><div style="background:#f59e0b;color:white;text-align:center;padding:10px;position:fixed;top:0;width:100%;z-index:9999;">‚ö†Ô∏è DEMO MODE: Using simulated data for preview<\/div><div style="height:50px;"><\/div>/' docs/index.html
        fi
        
    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: docs/
        
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
      
    - name: Create deployment summary
      run: |
        echo "## üìä Static Dashboard Deployment" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** ‚úÖ Deployed Successfully" >> $GITHUB_STEP_SUMMARY
        echo "**Time:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "**Dashboard URL:** https://kafka2306.github.io/nonfarmpayroll/" >> $GITHUB_STEP_SUMMARY
        echo "**Data Mode:** ${{ github.event.inputs.use_demo_data == 'true' && 'Demo Data' || 'Existing Data' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "This deployment includes only the dashboard interface." >> $GITHUB_STEP_SUMMARY
        echo "For data updates, use the 'Update Employment Statistics Dashboard' workflow." >> $GITHUB_STEP_SUMMARY